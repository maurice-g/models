# Faster R-CNN with Inception Resnet v2, Atrous version;
# Configured for Parts Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 18
    image_resizer {
      fixed_shape_resizer {
	height: 800
	width: 800
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_resnet_v2'
      first_stage_features_stride: 8
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
	scales: [0.125, 0.25, 0.5, 1.0, 2.0, 4.0]
	aspect_ratios: [0.18, 0.25, 0.5, 1.0, 2.0, 4.0, 6.0]
	height_stride: 8
	width_stride: 8
      }
    }
    first_stage_atrous_rate: 2
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
	l2_regularizer {
	  weight: 0.0
	}
      }
      initializer {
	truncated_normal_initializer {
	  stddev: 0.01
	}
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.5
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
	use_dropout: false
	dropout_keep_probability: 1.0
	fc_hyperparams {
	  op: FC
	  regularizer {
	    l2_regularizer {
	      weight: 0.0
	    }
	  }
	  initializer {
	    variance_scaling_initializer {
	      factor: 1.0
	      uniform: true
	      mode: FAN_AVG
	    }
	  }
	}
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
	score_threshold: 0.0
	iou_threshold: 0.6
	max_detections_per_class: 100
	max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    adam_optimizer: {
      learning_rate: {
	exponential_decay_learning_rate: {initial_learning_rate:0.00005}
      }
    }
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: "PATH_TO_BE_CONFIGURED/model.ckpt-GLOBAL_STEP"
  from_detection_checkpoint: true
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 200000
  data_augmentation_options {
    random_horizontal_flip {
    }
    random_vertical_flip {
    }
    random_rotation90 {
    }
    random_jitter_boxes {
      ratio: 0.05
    }
    random_crop_image {
      min_aspect_ratio: 0.33
      max_aspect_ratio: 1.33
      min_object_covered: 0.5
      random_coef: 0.15
      overlap_thresh: 0.02
    }
  }
  keep_checkpoint_every_n_hours: 500
}
train_input_reader: {
  tf_record_input_reader {
    input_path: "PATH_TO_BE_CONFIGURED/train-00000-of-00001"
  }
  label_map_path: "PATH_TO_BE_CONFIGURED/labelmap.pbtxt"
}

eval_config: {
  num_examples: NUM_EXAMPLES_TO_BE_CONFIGURED
  use_moving_averages: false
  max_evals: 0
  metrics_set: "coco_metrics"
  num_visualizations: 20
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: "PATH_TO_BE_CONFIGURED/test-00000-of-00001"
  }
  label_map_path: "PATH_TO_BE_CONFIGURED/labelmap.pbtxt"
  shuffle: false
  num_readers: 1
}
